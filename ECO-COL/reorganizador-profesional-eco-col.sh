#!/bin/bash

################################################################################
#  ECO-COL REORGANIZADOR PROFESIONAL v1.0
#  Herramienta de ReestructuraciÃ³n de Grado Empresarial
#
#  Autor: Equipo de Arquitectura de Staff Engineer
#  Fecha: 2026-01-18
#  PropÃ³sito: Transformar ECO-COL de cÃ³digo en desarrollo a estructura lista para producciÃ³n
#
#  CaracterÃ­sticas:
#  - ClasificaciÃ³n inteligente de archivos basada en reporte de auditorÃ­a
#  - MigraciÃ³n segura de archivos con creaciÃ³n de respaldo
#  - AnÃ¡lisis automÃ¡tico de dependencias
#  - GeneraciÃ³n de documentaciÃ³n
#  - VerificaciÃ³n de integridad
#  - Capacidad de rollback
################################################################################

set -euo pipefail  # Salir en error, variables indefinidas, fallos en pipes

# ============================================================================
# CONFIGURACIÃ“N Y GLOBALES
# ============================================================================

readonly SCRIPT_VERSION="1.0.0"
readonly SCRIPT_NAME="$(basename "$0")"
readonly TIMESTAMP=$(date +%Y%m%d_%H%M%S)
readonly LOG_FILE="/home/claude/reorganizacion_${TIMESTAMP}.log"
readonly BACKUP_DIR="/home/claude/ECO-COL-RESPALDO-${TIMESTAMP}"

# CÃ³digos de color para salida bonita
readonly RED='\033[0;31m'
readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BLUE='\033[0;34m'
readonly MAGENTA='\033[0;35m'
readonly CYAN='\033[0;36m'
readonly WHITE='\033[1;37m'
readonly NC='\033[0m' # Sin Color

# Seguimiento de estadÃ­sticas
declare -i TOTAL_ARCHIVOS=0
declare -i ARCHIVOS_MIGRADOS=0
declare -i ARCHIVOS_ARCHIVADOS=0
declare -i ERRORES=0

# ============================================================================
# FUNCIONES DE REGISTRO Y SALIDA
# ============================================================================

log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $*" | tee -a "$LOG_FILE"
}

log_info() {
    echo -e "${BLUE}â„¹${NC} $*" | tee -a "$LOG_FILE"
}

log_exito() {
    echo -e "${GREEN}âœ“${NC} $*" | tee -a "$LOG_FILE"
}

log_advertencia() {
    echo -e "${YELLOW}âš ${NC} $*" | tee -a "$LOG_FILE"
}

log_error() {
    echo -e "${RED}âœ—${NC} $*" | tee -a "$LOG_FILE"
    ((ERRORES++))
}

imprimir_encabezado() {
    echo ""
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${WHITE}$1${NC}"
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
}

imprimir_seccion() {
    echo ""
    echo -e "${MAGENTA}â”â”â” $1 â”â”â”${NC}"
    echo ""
}

# ============================================================================
# DEFINICIÃ“N DE ESTRUCTURA DE DIRECTORIOS
# ============================================================================

crear_estructura_directorios() {
    imprimir_seccion "Creando Estructura de Directorios Empresarial"
    
    local BASE_DIR="$1"
    
    # Definir la estructura completa
    local DIRS=(
        # 1. LÃ“GICA DE NEGOCIO
        "1-LOGICA-NEGOCIO/dominio/entidades"
        "1-LOGICA-NEGOCIO/dominio/objetos-valor"
        "1-LOGICA-NEGOCIO/casos-uso/paciente"
        "1-LOGICA-NEGOCIO/casos-uso/estudio"
        "1-LOGICA-NEGOCIO/casos-uso/dicom"
        "1-LOGICA-NEGOCIO/politicas/reglas-medicas"
        "1-LOGICA-NEGOCIO/politicas/reglas-validacion"
        
        # 2. CONTROLADORES
        "2-CONTROLADORES/api/rutas"
        "2-CONTROLADORES/api/endpoints"
        "2-CONTROLADORES/manejadores/dicom"
        "2-CONTROLADORES/manejadores/paciente"
        "2-CONTROLADORES/manejadores/estudio"
        "2-CONTROLADORES/middleware/autenticacion"
        "2-CONTROLADORES/middleware/validacion"
        "2-CONTROLADORES/middleware/registro"
        
        # 3. TRANSFORMADORES
        "3-TRANSFORMADORES/analizadores/dicom"
        "3-TRANSFORMADORES/analizadores/metadatos"
        "3-TRANSFORMADORES/serializadores/json"
        "3-TRANSFORMADORES/serializadores/xml"
        "3-TRANSFORMADORES/mapeadores/dtos"
        "3-TRANSFORMADORES/mapeadores/modelos-vista"
        
        # 4. VALIDADORES
        "4-VALIDADORES/esquemas/paciente"
        "4-VALIDADORES/esquemas/estudio"
        "4-VALIDADORES/esquemas/dicom"
        "4-VALIDADORES/reglas-negocio/medicas"
        "4-VALIDADORES/reglas-negocio/integridad-datos"
        "4-VALIDADORES/sanitizadores"
        
        # 5. DATOS
        "5-DATOS/almacenamiento/indexeddb"
        "5-DATOS/almacenamiento/localstorage"
        "5-DATOS/repositorios/paciente"
        "5-DATOS/repositorios/estudio"
        "5-DATOS/repositorios/dicom"
        "5-DATOS/migraciones"
        "5-DATOS/semillas"
        
        # 6. DESPLIEGUE
        "6-DESPLIEGUE/desarrollo/configuracion"
        "6-DESPLIEGUE/desarrollo/scripts"
        "6-DESPLIEGUE/staging/configuracion"
        "6-DESPLIEGUE/staging/scripts"
        "6-DESPLIEGUE/produccion/configuracion"
        "6-DESPLIEGUE/produccion/scripts"
        
        # 7. PRUEBAS
        "7-PRUEBAS/unitarias/logica-negocio"
        "7-PRUEBAS/unitarias/controladores"
        "7-PRUEBAS/unitarias/transformadores"
        "7-PRUEBAS/integracion/api"
        "7-PRUEBAS/integracion/dicom"
        "7-PRUEBAS/e2e/flujos-trabajo"
        "7-PRUEBAS/fixtures/muestras-dicom"
        "7-PRUEBAS/fixtures/datos-pacientes"
        
        # 8. DOCUMENTACIÃ“N
        "8-DOCUMENTACION/arquitectura/diagramas"
        "8-DOCUMENTACION/arquitectura/decisiones"
        "8-DOCUMENTACION/api/openapi"
        "8-DOCUMENTACION/api/ejemplos"
        "8-DOCUMENTACION/guias-usuario/hospital-1"
        "8-DOCUMENTACION/guias-usuario/hospital-2"
        "8-DOCUMENTACION/desarrollo/configuracion"
        "8-DOCUMENTACION/desarrollo/contribucion"
        
        # 9. HERRAMIENTAS
        "9-HERRAMIENTAS/scripts/compilacion"
        "9-HERRAMIENTAS/scripts/despliegue"
        "9-HERRAMIENTAS/scripts/migraciones"
        "9-HERRAMIENTAS/instaladores/fase-1"
        "9-HERRAMIENTAS/instaladores/fase-2"
        "9-HERRAMIENTAS/utilidades/herramientas-dicom"
        "9-HERRAMIENTAS/utilidades/ayudas-desarrollo"
        
        # ARCHIVO (para archivos obsoletos)
        "ARCHIVO/versiones/v0-1"
        "ARCHIVO/versiones/v2-3-4"
        "ARCHIVO/experimental"
        "ARCHIVO/obsoleto"
    )
    
    for dir in "${DIRS[@]}"; do
        local ruta_completa="${BASE_DIR}/${dir}"
        if mkdir -p "$ruta_completa"; then
            log_exito "Creado: ${dir}"
        else
            log_error "Fallo al crear: ${dir}"
        fi
    done
    
    # Crear archivos README en cada secciÃ³n principal
    crear_readmes_secciones "$BASE_DIR"
}

crear_readmes_secciones() {
    local BASE_DIR="$1"
    
    # README 1-LOGICA-NEGOCIO
    cat > "${BASE_DIR}/1-LOGICA-NEGOCIO/README.md" <<'EOF'
# ğŸ“‹ Capa de LÃ“GICA DE NEGOCIO

Esta capa contiene la lÃ³gica de dominio central y las reglas de negocio para ECO-COL.

## Estructura

- `dominio/` - Entidades del dominio central y objetos de valor
- `casos-uso/` - LÃ³gica de negocio especÃ­fica de la aplicaciÃ³n
- `politicas/` - PolÃ­ticas mÃ©dicas y de validaciÃ³n

## Principios

- LÃ³gica de negocio pura (sin UI, sin infraestructura)
- Independiente de frameworks
- Altamente testeable
- Principio de Responsabilidad Ãšnica

## Dependencias

Esta capa NO debe depender de:
- Controladores
- Capa de datos
- Frameworks externos
EOF

    # README 2-CONTROLADORES
    cat > "${BASE_DIR}/2-CONTROLADORES/README.md" <<'EOF'
# ğŸ® Capa de CONTROLADORES

Esta capa maneja las peticiones HTTP/API y las interacciones de usuario.

## Estructura

- `api/` - Rutas y endpoints de API
- `manejadores/` - Manejadores de peticiones
- `middleware/` - AutenticaciÃ³n, validaciÃ³n, registro

## Responsabilidades

- ValidaciÃ³n de peticiones
- Formateo de respuestas
- Manejo de errores
- AutenticaciÃ³n/AutorizaciÃ³n

## Dependencias

- Puede usar: LÃ³gica de Negocio, Transformadores, Validadores
- No puede usar: Acceso directo a datos (debe ir a travÃ©s de repositorios)
EOF

    # README 5-DATOS
    cat > "${BASE_DIR}/5-DATOS/README.md" <<'EOF'
# ğŸ’¾ Capa de DATOS

Esta capa gestiona toda la persistencia y recuperaciÃ³n de datos.

## Estructura

- `almacenamiento/` - Implementaciones de IndexedDB y localStorage
- `repositorios/` - Patrones de acceso a datos
- `migraciones/` - Migraciones de versiÃ³n de esquema
- `semillas/` - Datos de prueba y demostraciÃ³n

## Patrones Clave

- PatrÃ³n Repository para acceso a datos
- Sistema de migraciÃ³n para evoluciÃ³n de esquema
- Estrategia de cachÃ© para rendimiento

## Almacenamiento DICOM

Todos los archivos DICOM se almacenan en IndexedDB con:
- Checksums SHA-256 para integridad
- IndexaciÃ³n de metadatos para consultas rÃ¡pidas
- CompresiÃ³n para eficiencia de espacio
EOF

    # README 7-PRUEBAS
    cat > "${BASE_DIR}/7-PRUEBAS/README.md" <<'EOF'
# ğŸ§ª Suite de PRUEBAS

Cobertura de pruebas comprehensiva para ECO-COL.

## Tipos de Pruebas

### Pruebas Unitarias (`unitarias/`)
- Prueban funciones/clases individuales de forma aislada
- EjecuciÃ³n rÃ¡pida
- Sin dependencias externas

### Pruebas de IntegraciÃ³n (`integracion/`)
- Prueban interacciones entre componentes
- Pueden usar IndexedDB real
- Prueban pipeline de procesamiento DICOM

### Pruebas E2E (`e2e/`)
- Pruebas de flujo de trabajo completo
- Flujos Hospital #1 â†’ #2 â†’ #1
- ValidaciÃ³n de viaje de usuario

## Ejecutar Pruebas

```bash
# Ejecutar todas las pruebas
npm test

# Ejecutar suite especÃ­fica
npm test -- unitarias/logica-negocio

# Ejecutar con cobertura
npm test -- --coverage
```
EOF

    log_exito "Archivos README de secciones creados"
}

# ============================================================================
# MOTOR DE CLASIFICACIÃ“N DE ARCHIVOS
# ============================================================================

clasificar_archivo() {
    local archivo="$1"
    local nombrearchivo=$(basename "$archivo")
    local extension="${nombrearchivo##*.}"
    
    # Archivos de producciÃ³n (basado en puntuaciÃ³n del reporte de auditorÃ­a)
    if [[ "$nombrearchivo" =~ ULTIMATE.*V6.*FUSION ]] || 
       [[ "$nombrearchivo" =~ FINAL.*V5.1.*MEJORADO ]] ||
       [[ "$nombrearchivo" =~ FINAL.*V5.0.*COMPLETO ]]; then
        echo "PRODUCCION"
        return
    fi
    
    # Serie PRO V4.x (candidatos para producciÃ³n)
    if [[ "$nombrearchivo" =~ PRO.*V4\.[0-9].*FINAL ]]; then
        echo "CANDIDATO_PRODUCCION"
        return
    fi
    
    # Scripts de instalaciÃ³n por fase
    if [[ "$nombrearchivo" =~ install.*fase.*[0-9]+\.sh ]] ||
       [[ "$nombrearchivo" =~ install-fase-[0-9]+\.sh ]]; then
        echo "INSTALADOR"
        return
    fi
    
    # DocumentaciÃ³n
    if [[ "$nombrearchivo" =~ README\.txt ]] ||
       [[ "$nombrearchivo" =~ COMO-USAR ]] ||
       [[ "$nombrearchivo" =~ eco_col_final_analysis\.txt ]]; then
        echo "DOCUMENTACION"
        return
    fi
    
    # Archivos de Test/Demo
    if [[ "$nombrearchivo" =~ [Dd]emo ]] ||
       [[ "$nombrearchivo" =~ [Tt]est ]] ||
       [[ "$nombrearchivo" =~ diagrama ]]; then
        echo "ARCHIVO"
        return
    fi
    
    # Versiones antiguas
    if [[ "$nombrearchivo" =~ FASE[1-3] ]] ||
       [[ "$nombrearchivo" =~ V[0-3]\. ]] ||
       [[ "$archivo" =~ ECO-COL---V0-1 ]]; then
        echo "ARCHIVO"
        return
    fi
    
    # Archivos de backend
    if [[ "$nombrearchivo" =~ [Bb]ackend ]] ||
       [[ "$nombrearchivo" =~ [Ss]erver ]]; then
        echo "BACKEND"
        return
    fi
    
    # Utilidades
    if [[ "$nombrearchivo" =~ auditor\.sh ]] ||
       [[ "$nombrearchivo" =~ fix ]]; then
        echo "UTILIDAD"
        return
    fi
    
    # Por defecto: archivar archivos desconocidos
    echo "ARCHIVO"
}

# ============================================================================
# MIGRACIÃ“N INTELIGENTE DE ARCHIVOS
# ============================================================================

migrar_archivo() {
    local origen="$1"
    local clasificacion="$2"
    local base_destino="$3"
    
    local nombrearchivo=$(basename "$origen")
    local ruta_destino=""
    
    case "$clasificacion" in
        PRODUCCION)
            # Archivo principal de producciÃ³n va a la raÃ­z de la estructura final
            ruta_destino="${base_destino}/ECO-COL-PRODUCCION.html"
            cp "$origen" "$ruta_destino"
            log_exito "Archivo de producciÃ³n: ${nombrearchivo} â†’ ECO-COL-PRODUCCION.html"
            ((ARCHIVOS_MIGRADOS++))
            ;;
            
        CANDIDATO_PRODUCCION)
            # Mantener como alternativa/respaldo
            ruta_destino="${base_destino}/6-DESPLIEGUE/staging/${nombrearchivo}"
            cp "$origen" "$ruta_destino"
            log_info "Candidato staging: ${nombrearchivo}"
            ((ARCHIVOS_MIGRADOS++))
            ;;
            
        INSTALADOR)
            # Extraer nÃºmero de fase y organizar
            if [[ "$nombrearchivo" =~ fase.?([0-9]+) ]]; then
                local fase="${BASH_REMATCH[1]}"
                ruta_destino="${base_destino}/9-HERRAMIENTAS/instaladores/fase-${fase}/${nombrearchivo}"
            else
                ruta_destino="${base_destino}/9-HERRAMIENTAS/instaladores/${nombrearchivo}"
            fi
            cp "$origen" "$ruta_destino"
            chmod +x "$ruta_destino" 2>/dev/null || true
            log_exito "Instalador: ${nombrearchivo} â†’ fase-${fase}/"
            ((ARCHIVOS_MIGRADOS++))
            ;;
            
        DOCUMENTACION)
            ruta_destino="${base_destino}/8-DOCUMENTACION/${nombrearchivo}"
            cp "$origen" "$ruta_destino"
            log_exito "DocumentaciÃ³n: ${nombrearchivo}"
            ((ARCHIVOS_MIGRADOS++))
            ;;
            
        BACKEND)
            ruta_destino="${base_destino}/6-DESPLIEGUE/desarrollo/${nombrearchivo}"
            cp "$origen" "$ruta_destino"
            log_info "Componente backend: ${nombrearchivo}"
            ((ARCHIVOS_MIGRADOS++))
            ;;
            
        UTILIDAD)
            ruta_destino="${base_destino}/9-HERRAMIENTAS/utilidades/${nombrearchivo}"
            cp "$origen" "$ruta_destino"
            chmod +x "$ruta_destino" 2>/dev/null || true
            log_exito "Utilidad: ${nombrearchivo}"
            ((ARCHIVOS_MIGRADOS++))
            ;;
            
        ARCHIVO)
            # Organizar por versiÃ³n
            if [[ "$origen" =~ V0-1 ]] || [[ "$nombrearchivo" =~ FASE[1-3] ]]; then
                ruta_destino="${base_destino}/ARCHIVO/versiones/v0-1/${nombrearchivo}"
            elif [[ "$origen" =~ V2-3-4 ]] || [[ "$nombrearchivo" =~ V[2-4]\. ]]; then
                ruta_destino="${base_destino}/ARCHIVO/versiones/v2-3-4/${nombrearchivo}"
            else
                ruta_destino="${base_destino}/ARCHIVO/obsoleto/${nombrearchivo}"
            fi
            cp "$origen" "$ruta_destino"
            log_advertencia "Archivado: ${nombrearchivo}"
            ((ARCHIVOS_ARCHIVADOS++))
            ;;
    esac
}

# ============================================================================
# PROCESO PRINCIPAL DE MIGRACIÃ“N
# ============================================================================

realizar_migracion() {
    local dir_origen="$1"
    local dir_destino="$2"
    
    imprimir_seccion "Analizando y Migrando Archivos"
    
    # Buscar todos los archivos HTML
    log_info "Escaneando archivos HTML..."
    while IFS= read -r -d '' archivo; do
        ((TOTAL_ARCHIVOS++))
        
        local clasificacion=$(clasificar_archivo "$archivo")
        migrar_archivo "$archivo" "$clasificacion" "$dir_destino"
        
    done < <(find "$dir_origen" -type f -name "*.html" -print0)
    
    # Buscar todos los scripts shell
    log_info "Escaneando scripts shell..."
    while IFS= read -r -d '' archivo; do
        ((TOTAL_ARCHIVOS++))
        
        local clasificacion=$(clasificar_archivo "$archivo")
        migrar_archivo "$archivo" "$clasificacion" "$dir_destino"
        
    done < <(find "$dir_origen" -type f -name "*.sh" -print0)
    
    # Buscar toda la documentaciÃ³n
    log_info "Escaneando documentaciÃ³n..."
    while IFS= read -r -d '' archivo; do
        ((TOTAL_ARCHIVOS++))
        
        local clasificacion=$(clasificar_archivo "$archivo")
        migrar_archivo "$archivo" "$clasificacion" "$dir_destino"
        
    done < <(find "$dir_origen" -type f \( -name "*.txt" -o -name "*.md" \) -print0)
}

# ============================================================================
# GENERACIÃ“N DE DOCUMENTACIÃ“N
# ============================================================================

generar_reporte_migracion() {
    local dir_destino="$1"
    local archivo_reporte="${dir_destino}/REPORTE-MIGRACION-${TIMESTAMP}.md"
    
    imprimir_seccion "Generando Reporte de MigraciÃ³n"
    
    cat > "$archivo_reporte" <<EOF
# ğŸ—ï¸ Reporte de ReorganizaciÃ³n Profesional ECO-COL

**Fecha:** $(date)
**VersiÃ³n del Script:** ${SCRIPT_VERSION}
**Estado:** ${ERRORES} errores encontrados

---

## ğŸ“Š EstadÃ­sticas de MigraciÃ³n

- **Total de Archivos Procesados:** ${TOTAL_ARCHIVOS}
- **Archivos Migrados:** ${ARCHIVOS_MIGRADOS}
- **Archivos Archivados:** ${ARCHIVOS_ARCHIVADOS}
- **Errores:** ${ERRORES}

---

## ğŸ¯ Archivos de ProducciÃ³n

Los siguientes archivos fueron identificados como listos para producciÃ³n:

EOF

    # Listar archivo de producciÃ³n
    if [[ -f "${dir_destino}/ECO-COL-PRODUCCION.html" ]]; then
        echo "- âœ… ECO-COL-PRODUCCION.html (Archivo principal de despliegue)" >> "$archivo_reporte"
    fi
    
    cat >> "$archivo_reporte" <<EOF

---

## ğŸ“ Nueva Estructura de Directorios

\`\`\`
ECO-COL-FINAL/
â”œâ”€â”€ 1-LOGICA-NEGOCIO/    # LÃ³gica de dominio central
â”œâ”€â”€ 2-CONTROLADORES/     # API y manejadores de peticiones
â”œâ”€â”€ 3-TRANSFORMADORES/   # Capa de transformaciÃ³n de datos
â”œâ”€â”€ 4-VALIDADORES/       # ValidaciÃ³n y sanitizaciÃ³n
â”œâ”€â”€ 5-DATOS/             # Capa de persistencia (IndexedDB)
â”œâ”€â”€ 6-DESPLIEGUE/        # Configuraciones de entorno
â”œâ”€â”€ 7-PRUEBAS/           # Suites de pruebas
â”œâ”€â”€ 8-DOCUMENTACION/     # DocumentaciÃ³n
â”œâ”€â”€ 9-HERRAMIENTAS/      # Scripts y utilidades
â””â”€â”€ ARCHIVO/             # Versiones histÃ³ricas
\`\`\`

---

## ğŸš€ PrÃ³ximos Pasos

### 1. Verificar Archivo de ProducciÃ³n
\`\`\`bash
# Abrir en navegador y probar
open ECO-COL-PRODUCCION.html
\`\`\`

### 2. Revisar Candidatos en Staging
\`\`\`bash
ls -lh 6-DESPLIEGUE/staging/
\`\`\`

### 3. Ejecutar Pruebas (cuando estÃ©n implementadas)
\`\`\`bash
cd 7-PRUEBAS
npm test
\`\`\`

### 4. Desplegar a ProducciÃ³n
\`\`\`bash
cd 6-DESPLIEGUE/produccion
./desplegar.sh
\`\`\`

---

## ğŸ“ Notas

- Todos los archivos obsoletos preservados en \`ARCHIVO/\`
- Scripts de instalaciÃ³n organizados por fase en \`9-HERRAMIENTAS/instaladores/\`
- Respaldo original: \`${BACKUP_DIR}\`

---

## âš ï¸ Advertencias

EOF

    if [[ $ERRORES -gt 0 ]]; then
        echo "- ${ERRORES} errores ocurrieron durante la migraciÃ³n. Revisar ${LOG_FILE}" >> "$archivo_reporte"
    else
        echo "- No se detectaron errores âœ“" >> "$archivo_reporte"
    fi
    
    cat >> "$archivo_reporte" <<EOF

---

## ğŸ”„ Procedimiento de Rollback

Si surgen problemas:

\`\`\`bash
# Rollback completo
rm -rf ECO-COL-FINAL/
cp -r ${BACKUP_DIR}/* ./

# Rollback parcial - restaurar archivo especÃ­fico
cp ${BACKUP_DIR}/ruta/al/archivo ./
\`\`\`

---

**Generado por:** ECO-COL Reorganizador Profesional v${SCRIPT_VERSION}
EOF

    log_exito "Reporte de migraciÃ³n creado: ${archivo_reporte}"
}

generar_readme_principal() {
    local dir_destino="$1"
    
    cat > "${dir_destino}/README.md" <<'EOF'
# ğŸ¥ ECO-COL - Plataforma Profesional de Tele-EcografÃ­a

**SoluciÃ³n de Imagen MÃ©dica de Grado Empresarial para la Colombia Rural**

[![Estado](https://img.shields.io/badge/estado-producciÃ³n-green)]()
[![VersiÃ³n](https://img.shields.io/badge/versiÃ³n-6.0-blue)]()
[![Licencia](https://img.shields.io/badge/licencia-Uso%20MÃ©dico-red)]()

---

## ğŸ¯ MisiÃ³n

Reducir la mortalidad materna en el Cauca rural, Colombia, proporcionando diagnÃ³stico ecogrÃ¡fico remoto en tiempo real, conectando centros de salud rurales con radiÃ³logos en PopayÃ¡n.

### MÃ©tricas Clave de Impacto (Proyectadas)
- **ReducciÃ³n del 30-40%** en traslados innecesarios de pacientes
- **15-30 minutos** de diagnÃ³stico remoto vs 3-5 horas de traslado fÃ­sico
- **$72M COP/aÃ±o** ahorrados en costos de traslado (estimaciÃ³n conservadora)
- **720 traslados/aÃ±o** evitados en 5 centros piloto

---

## ğŸ—ï¸ Arquitectura

Este proyecto sigue un patrÃ³n de **arquitectura en capas** para mÃ¡xima mantenibilidad y escalabilidad:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        INTERFAZ DE USUARIO (HTML/CSS/JS)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 2-CONTROLADORES â”‚  â† Manejo de peticiones, enrutamiento
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚            â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚1-LOG  â”‚   â”‚3-TRANSâ”‚   â”‚4-VALID â”‚  â† LÃ³gica de negocio,
â”‚NEGOCIOâ”‚   â”‚FORM   â”‚   â”‚ADORES  â”‚     transformaciones,
â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     validaciÃ³n
    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ 5-DATOS  â”‚  â† IndexedDB, persistencia
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Inicio RÃ¡pido

### Prerequisitos
- Navegador web moderno (Chrome 90+, Firefox 88+, Safari 14+)
- No se requiere servidor (funciona 100% del lado del cliente)
- Archivos DICOM para pruebas

### InstalaciÃ³n

```bash
# OpciÃ³n 1: Uso directo
open ECO-COL-PRODUCCION.html

# OpciÃ³n 2: Servidor local (recomendado para desarrollo)
cd 6-DESPLIEGUE/desarrollo
python3 -m http.server 8000
# Abrir http://localhost:8000/../../ECO-COL-PRODUCCION.html
```

### Roles de Usuario

**Hospital #1 (Centro PerifÃ©rico)**
1. Registrar paciente
2. Subir ecografÃ­a DICOM
3. Crear solicitud de estudio
4. Enviar a Hospital #2

**Hospital #2 (Centro de RadiologÃ­a - PopayÃ¡n)**
1. Revisar estudios entrantes
2. Ver DICOM en visor Cornerstone
3. Agregar diagnÃ³stico
4. Enviar de vuelta a Hospital #1

---

## ğŸ“ Estructura del Proyecto

```
ECO-COL-FINAL/
â”‚
â”œâ”€â”€ ECO-COL-PRODUCCION.html     â† Archivo principal de producciÃ³n
â”œâ”€â”€ README.md                    â† Este archivo
â”œâ”€â”€ REPORTE-MIGRACION-*.md       â† Historial de reorganizaciÃ³n
â”‚
â”œâ”€â”€ 1-LOGICA-NEGOCIO/
â”‚   â”œâ”€â”€ dominio/                 # Entidades Paciente, Estudio, DICOM
â”‚   â”œâ”€â”€ casos-uso/               # Flujos de trabajo de negocio
â”‚   â””â”€â”€ politicas/               # Reglas de validaciÃ³n mÃ©dica
â”‚
â”œâ”€â”€ 2-CONTROLADORES/
â”‚   â”œâ”€â”€ api/                     # API tipo REST (futuro)
â”‚   â”œâ”€â”€ manejadores/             # Manejadores de eventos
â”‚   â””â”€â”€ middleware/              # Auth, logging, validaciÃ³n
â”‚
â”œâ”€â”€ 3-TRANSFORMADORES/
â”‚   â”œâ”€â”€ analizadores/            # LÃ³gica de parser DICOM
â”‚   â”œâ”€â”€ serializadores/          # SerializaciÃ³n JSON/XML
â”‚   â””â”€â”€ mapeadores/              # Mapeo DTO
â”‚
â”œâ”€â”€ 4-VALIDADORES/
â”‚   â”œâ”€â”€ esquemas/                # Esquemas JSON
â”‚   â”œâ”€â”€ reglas-negocio/          # ValidaciÃ³n mÃ©dica
â”‚   â””â”€â”€ sanitizadores/           # SanitizaciÃ³n de entrada
â”‚
â”œâ”€â”€ 5-DATOS/
â”‚   â”œâ”€â”€ almacenamiento/          # ImplementaciÃ³n IndexedDB
â”‚   â”œâ”€â”€ repositorios/            # Capa de acceso a datos
â”‚   â”œâ”€â”€ migraciones/             # Migraciones de esquema
â”‚   â””â”€â”€ semillas/                # Datos de prueba
â”‚
â”œâ”€â”€ 6-DESPLIEGUE/
â”‚   â”œâ”€â”€ desarrollo/              # Entorno de desarrollo
â”‚   â”œâ”€â”€ staging/                 # Pre-producciÃ³n
â”‚   â””â”€â”€ produccion/              # Configuraciones de producciÃ³n
â”‚
â”œâ”€â”€ 7-PRUEBAS/
â”‚   â”œâ”€â”€ unitarias/               # Pruebas unitarias
â”‚   â”œâ”€â”€ integracion/             # Pruebas de integraciÃ³n
â”‚   â”œâ”€â”€ e2e/                     # Pruebas end-to-end
â”‚   â””â”€â”€ fixtures/                # Datos de prueba
â”‚
â”œâ”€â”€ 8-DOCUMENTACION/
â”‚   â”œâ”€â”€ arquitectura/            # Documentos de diseÃ±o del sistema
â”‚   â”œâ”€â”€ api/                     # DocumentaciÃ³n de API
â”‚   â””â”€â”€ guias-usuario/           # Manuales de usuario
â”‚
â”œâ”€â”€ 9-HERRAMIENTAS/
â”‚   â”œâ”€â”€ scripts/                 # Scripts de compilaciÃ³n/despliegue
â”‚   â”œâ”€â”€ instaladores/            # Instaladores basados en fases
â”‚   â””â”€â”€ utilidades/              # Ayudas de desarrollo
â”‚
â””â”€â”€ ARCHIVO/                     # Versiones histÃ³ricas (V0-V5)
```

---

## ğŸ”§ Stack TecnolÃ³gico

### TecnologÃ­as Centrales
- **Procesamiento DICOM:** Cornerstone.js, dicom-parser
- **Almacenamiento:** IndexedDB (persistente, capaz de trabajar offline)
- **Framework UI:** JavaScript vanilla (sin dependencias)
- **Procesamiento de ImÃ¡genes:** API Canvas de HTML5

### LibrerÃ­as Clave
- `cornerstone-core` v2.6.1
- `cornerstone-tools` v6.0.6
- `dicom-parser` v1.8.13
- `cornerstone-wado-image-loader` v4.1.2

### Infraestructura
- 100% del lado del cliente (no se requiere backend)
- Funciona offline despuÃ©s de la carga inicial
- Compatible con mÃºltiples navegadores

---

## ğŸ§ª Pruebas

```bash
# Ejecutar todas las pruebas
cd 7-PRUEBAS
npm test

# Ejecutar suite especÃ­fica
npm test -- unitarias/logica-negocio

# Pruebas de integraciÃ³n (requiere DICOMs de muestra)
npm test -- integracion/dicom

# Pruebas de flujo de trabajo E2E
npm test -- e2e/flujo-hospitales
```

---

## ğŸ“Š MÃ©tricas de Rendimiento

- **Tiempo de Carga DICOM:** <2s para ecografÃ­a tÃ­pica (5-10MB)
- **Renderizado Multi-frame:** 30 FPS (reproducciÃ³n suave)
- **Escritura IndexedDB:** <500ms para estudio completo
- **Transferencia de Red:** N/A (funciona offline)
- **Uso de Memoria:** <200MB para sesiÃ³n promedio

---

## ğŸš€ Despliegue

### Desarrollo
```bash
cd 6-DESPLIEGUE/desarrollo
./iniciar-servidor-dev.sh
```

### Staging
```bash
cd 6-DESPLIEGUE/staging
./desplegar-staging.sh
```

### ProducciÃ³n
```bash
cd 6-DESPLIEGUE/produccion
./desplegar-prod.sh
```

---

## ğŸ¤ ContribuciÃ³n

Ver [CONTRIBUCION.md](8-DOCUMENTACION/desarrollo/CONTRIBUCION.md) para:
- GuÃ­a de estilo de cÃ³digo
- Flujo de trabajo Git
- Proceso de pull request
- Requisitos de pruebas

---

## ğŸ“„ Licencia

Licencia de Uso MÃ©dico - Ver [LICENSE.md](LICENSE.md)

**Importante:** Este software estÃ¡ diseÃ±ado para apoyo al diagnÃ³stico mÃ©dico. Todos los resultados deben ser validados por profesionales mÃ©dicos licenciados.

---

## ğŸ†˜ Soporte

- **DocumentaciÃ³n:** [8-DOCUMENTACION/](8-DOCUMENTACION/)
- **Issues:** GitHub Issues (si aplica)
- **Preguntas MÃ©dicas:** Contactar Hospital Universitario San JosÃ©, PopayÃ¡n

---

## ğŸ† CrÃ©ditos

**Equipo del Proyecto:**
- Asesores ClÃ­nicos: Hospital Universitario San JosÃ©
- LÃ­der TÃ©cnico: [Tu Nombre]
- Con el apoyo de: Universidad del Cauca, GobernaciÃ³n del Cauca

**Financiamiento:**
- MinSalud Plan Nacional de Salud Rural
- CooperaciÃ³n Internacional (USAID, OPS)

---

## ğŸ“ˆ Hoja de Ruta

### Fase 1 (Actual)
- âœ… Visor DICOM central
- âœ… Flujo de trabajo hospital a hospital
- âœ… Persistencia IndexedDB

### Fase 2 (Q2 2026)
- â¬œ AplicaciÃ³n mÃ³vil (React Native)
- â¬œ Respaldo en la nube (opcional)
- â¬œ Mediciones avanzadas

### Fase 3 (Q3 2026)
- â¬œ DiagnÃ³stico asistido por IA
- â¬œ IntegraciÃ³n con SIRENAGEST
- â¬œ Red multi-hospitalaria

---

**Hecho con â¤ï¸ para la Salud Rural en Colombia**
EOF

    log_exito "README.md principal creado"
}

# ============================================================================
# RESPALDO Y SEGURIDAD
# ============================================================================

crear_respaldo() {
    local dir_origen="$1"
    
    imprimir_seccion "Creando Respaldo de Seguridad"
    
    if [[ ! -d "$dir_origen" ]]; then
        log_error "El directorio origen no existe: $dir_origen"
        return 1
    fi
    
    log_info "Respaldando a: ${BACKUP_DIR}"
    
    if cp -r "$dir_origen" "$BACKUP_DIR"; then
        log_exito "Respaldo creado exitosamente"
        log_info "TamaÃ±o del respaldo: $(du -sh "$BACKUP_DIR" | cut -f1)"
        return 0
    else
        log_error "Â¡Fallo el respaldo!"
        return 1
    fi
}

# ============================================================================
# VERIFICACIÃ“N E INTEGRIDAD
# ============================================================================

verificar_migracion() {
    local dir_destino="$1"
    
    imprimir_seccion "Verificando Integridad de la MigraciÃ³n"
    
    local verificaciones_pasadas=0
    local verificaciones_totales=5
    
    # VerificaciÃ³n 1: Archivo de producciÃ³n existe
    if [[ -f "${dir_destino}/ECO-COL-PRODUCCION.html" ]]; then
        log_exito "Archivo de producciÃ³n existe"
        ((verificaciones_pasadas++))
    else
        log_error "Â¡Archivo de producciÃ³n faltante!"
    fi
    
    # VerificaciÃ³n 2: Todos los directorios principales creados
    if [[ -d "${dir_destino}/1-LOGICA-NEGOCIO" ]] && 
       [[ -d "${dir_destino}/5-DATOS" ]] &&
       [[ -d "${dir_destino}/7-PRUEBAS" ]]; then
        log_exito "Directorios centrales existen"
        ((verificaciones_pasadas++))
    else
        log_error "Â¡Faltan directorios centrales!"
    fi
    
    # VerificaciÃ³n 3: Instaladores migrados
    local contador_instaladores=$(find "${dir_destino}/9-HERRAMIENTAS/instaladores" -name "*.sh" 2>/dev/null | wc -l)
    if [[ $contador_instaladores -gt 0 ]]; then
        log_exito "Instaladores migrados ($contador_instaladores archivos)"
        ((verificaciones_pasadas++))
    else
        log_advertencia "No se encontraron instaladores"
    fi
    
    # VerificaciÃ³n 4: DocumentaciÃ³n presente
    if [[ -f "${dir_destino}/README.md" ]]; then
        log_exito "README principal existe"
        ((verificaciones_pasadas++))
    else
        log_error "Â¡README principal faltante!"
    fi
    
    # VerificaciÃ³n 5: El archivo tiene contenido
    local contador_archivo=$(find "${dir_destino}/ARCHIVO" -type f 2>/dev/null | wc -l)
    if [[ $contador_archivo -gt 0 ]]; then
        log_exito "Archivo contiene ${contador_archivo} archivos"
        ((verificaciones_pasadas++))
    else
        log_advertencia "El archivo estÃ¡ vacÃ­o"
    fi
    
    echo ""
    log_info "VerificaciÃ³n: ${verificaciones_pasadas}/${verificaciones_totales} verificaciones pasadas"
    
    if [[ $verificaciones_pasadas -eq $verificaciones_totales ]]; then
        return 0
    else
        return 1
    fi
}

# ============================================================================
# ESTADÃSTICAS FINALES Y RESUMEN
# ============================================================================

imprimir_resumen() {
    imprimir_encabezado "REORGANIZACIÃ“N COMPLETADA"
    
    echo -e "${GREEN}âœ“ Proyecto ECO-COL reorganizado exitosamente${NC}"
    echo ""
    echo -e "${CYAN}EstadÃ­sticas:${NC}"
    echo -e "  Archivos procesados: ${WHITE}${TOTAL_ARCHIVOS}${NC}"
    echo -e "  Archivos migrados:   ${GREEN}${ARCHIVOS_MIGRADOS}${NC}"
    echo -e "  Archivos archivados: ${YELLOW}${ARCHIVOS_ARCHIVADOS}${NC}"
    echo -e "  Errores:             ${RED}${ERRORES}${NC}"
    echo ""
    echo -e "${CYAN}Salidas Clave:${NC}"
    echo -e "  Archivo de producciÃ³n: ${GREEN}ECO-COL-FINAL/ECO-COL-PRODUCCION.html${NC}"
    echo -e "  DocumentaciÃ³n:         ${BLUE}ECO-COL-FINAL/README.md${NC}"
    echo -e "  Registro de migraciÃ³n: ${BLUE}${LOG_FILE}${NC}"
    echo -e "  UbicaciÃ³n de respaldo: ${YELLOW}${BACKUP_DIR}${NC}"
    echo ""
    echo -e "${CYAN}PrÃ³ximos Pasos:${NC}"
    echo -e "  1. Revisar reporte de migraciÃ³n en ECO-COL-FINAL/"
    echo -e "  2. Probar archivo de producciÃ³n en navegador"
    echo -e "  3. Verificar todos los instaladores en 9-HERRAMIENTAS/"
    echo -e "  4. Leer 8-DOCUMENTACION/ para guÃ­a de despliegue"
    echo ""
    
    if [[ $ERRORES -eq 0 ]]; then
        echo -e "${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
        echo -e "${GREEN}â•‘  Â¡MIGRACIÃ“N EXITOSA - SIN ERRORES!   â•‘${NC}"
        echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    else
        echo -e "${RED}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
        echo -e "${RED}â•‘  MIGRACIÃ“N COMPLETADA CON ERRORES     â•‘${NC}"
        echo -e "${RED}â•‘  Revisar ${LOG_FILE}  â•‘${NC}"
        echo -e "${RED}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    fi
    echo ""
}

# ============================================================================
# EJECUCIÃ“N PRINCIPAL
# ============================================================================

principal() {
    imprimir_encabezado "ECO-COL REORGANIZADOR PROFESIONAL v${SCRIPT_VERSION}"
    
    # Solicitar directorio origen
    echo -e "${CYAN}Ingrese la ruta del directorio origen (ej: /mnt/user-data/uploads):${NC}"
    read -r DIR_ORIGEN
    
    # Validar directorio origen
    if [[ ! -d "$DIR_ORIGEN" ]]; then
        log_error "El directorio origen no existe: ${DIR_ORIGEN}"
        exit 1
    fi
    
    local DIR_DESTINO="/home/claude/ECO-COL-FINAL"
    
    echo ""
    log_info "Origen: ${DIR_ORIGEN}"
    log_info "Destino: ${DIR_DESTINO}"
    log_info "Respaldo: ${BACKUP_DIR}"
    echo ""
    
    read -p "Â¿Proceder con la reorganizaciÃ³n? (si/no): " -r
    if [[ ! $REPLY =~ ^[Ss][Ii]$ ]]; then
        log_advertencia "OperaciÃ³n cancelada por el usuario"
        exit 0
    fi
    
    # Ejecutar pipeline de reorganizaciÃ³n
    crear_respaldo "$DIR_ORIGEN" || exit 1
    
    crear_estructura_directorios "$DIR_DESTINO"
    
    realizar_migracion "$DIR_ORIGEN" "$DIR_DESTINO"
    
    generar_reporte_migracion "$DIR_DESTINO"
    
    generar_readme_principal "$DIR_DESTINO"
    
    verificar_migracion "$DIR_DESTINO"
    
    imprimir_resumen
    
    log_info "Registro completo disponible en: ${LOG_FILE}"
}

# Punto de entrada
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    principal "$@"
fi
